import json
import requests
import datetime
import os
import re
import time
from bs4 import BeautifulSoup
from typing import List, Dict, Any

class BidMonitor:
    def __init__(self):
        # åˆå§‹åŒ–æ–‡ä»¶è·¯å¾„
        self.original_file = "hx.json"
        self.parsed_file = "hx_parsed.json"
        
        # ä¼ä¸šå¾®ä¿¡é…ç½®
        self.webhook_url = os.getenv("QYWX_URL")
        self.webhook_zb_url = os.getenv("QYWX_ZB_URL")
        
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        if not self.webhook_url:
            print("è­¦å‘Šï¼šQYWX_URLç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œæ— æ³•å‘é€å¸¸è§„é€šçŸ¥")
        if not self.webhook_zb_url:
            print("è­¦å‘Šï¼šQYWX_ZB_URLç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œæ— æ³•å‘é€ä¸­æ ‡ç‰¹åˆ«é€šçŸ¥")
        
        # APIé…ç½®
        self.api_url = "https://ggzy.sc.yichang.gov.cn/EpointWebBuilder/rest/secaction/getSecInfoListYzm"
        self.site_guid = "7eb5f7f1-9041-43ad-8e13-8fcb82ea831a"
        self.category_num = "003001004"  # ä¸­æ ‡å€™é€‰äººç±»åˆ«
        self.page_size = 6
        self.latest_new_count = 0  # è·Ÿè¸ªæœ€æ–°æ–°å¢æ•°é‡
        self.base_url = "https://ggzy.sc.yichang.gov.cn"  # åŸºç¡€URL
        
    def _load_json_file(self, filename: str) -> List[Dict]:
        """åŠ è½½JSONæ–‡ä»¶"""
        try:
            if os.path.exists(filename):
                with open(filename, 'r', encoding='utf-8') as f:
                    return json.load(f)
            return []
        except Exception as e:
            print(f"[æ–‡ä»¶é”™è¯¯] åŠ è½½ {filename} å¤±è´¥: {str(e)}")
            return []

    def _save_json_file(self, filename: str, data: List[Dict]):
        """ä¿å­˜JSONæ–‡ä»¶"""
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"[æ–‡ä»¶é”™è¯¯] ä¿å­˜ {filename} å¤±è´¥: {str(e)}")

    def _is_existing_record(self, new_item: Dict, existing: List[Dict]) -> bool:
        """æ£€æŸ¥è®°å½•æ˜¯å¦å·²å­˜åœ¨"""
        new_id = new_item.get("infoid")
        new_url = new_item.get("infourl")
        return any(
            item.get("infoid") == new_id or 
            item.get("infourl") == new_url
            for item in existing
        )
    
    def reparse_all_data(self):
        """é‡æ–°è§£ææ‰€æœ‰åŸå§‹æ•°æ®"""
        original_data = self._load_json_file(self.original_file)
        parsed_data = []
        
        for item in original_data:
            parsed_record = {
                "infoid": item.get("infoid"),
                "infourl": item.get("infourl"),
                "parsed_data": self._parse_html_content(item),
                "raw_data": {
                    "title": item.get("title"),
                    "infodate": item.get("infodate")
                }
            }
            parsed_data.append(parsed_record)
        
        self._save_json_file(self.parsed_file, parsed_data)
        print(f"[é‡è§£æå®Œæˆ] å…±è§£æ {len(parsed_data)} æ¡æ•°æ®å¹¶ä¿å­˜åˆ° {self.parsed_file}")

    def fetch_latest_data(self) -> List[Dict]:
        """è·å–æœ€æ–°æ‹›æ ‡æ•°æ®"""
        payload = {
            "siteGuid": self.site_guid,
            "categoryNum": self.category_num,
            "pageindex": "0",
            "pagesize": str(self.page_size),
            "content": "",
            "startdate": "",
            "enddate": "", 
            "xiqucode": ""
        }
        
        for attempt in range(3):
            try:
                response = requests.post(self.api_url, data=payload, timeout=30)
                response.raise_for_status()
                return response.json().get("custom", {}).get("infodata", [])
            except requests.exceptions.Timeout:
                print(f"[ç¬¬ {attempt+1} æ¬¡å°è¯•] è¯·æ±‚è¶…æ—¶")
            except requests.RequestException as e:
                print(f"[ç¬¬ {attempt+1} æ¬¡å°è¯•] è¯·æ±‚å¤±è´¥: {str(e)}")
            time.sleep(5)
        
        print("[æœ€ç»ˆå¤±è´¥] æ— æ³•è·å–æ•°æ®")
        return []

    def process_and_store_data(self) -> int:
        """å¤„ç†å¹¶å­˜å‚¨æ•°æ®"""
        new_raw_data = self.fetch_latest_data()
        if not new_raw_data:
            return 0

        existing_raw = self._load_json_file(self.original_file)
        new_items = [
            item for item in new_raw_data
            if not self._is_existing_record(item, existing_raw)
        ]
        
        if not new_items:
            return 0

        # ä¿å­˜åŸå§‹æ•°æ®
        updated_raw = existing_raw + new_items
        self._save_json_file(self.original_file, updated_raw)
        
        # è§£ææ–°æ•°æ®
        parsed_data = self._load_json_file(self.parsed_file)
        for item in new_items:
            parsed_record = {
                "infoid": item.get("infoid"),
                "infourl": item.get("infourl"),
                "parsed_data": self._parse_html_content(item),
                "raw_data": {
                    "title": item.get("title"),
                    "infodate": item.get("infodate")
                }
            }
            parsed_data.append(parsed_record)
        
        self._save_json_file(self.parsed_file, parsed_data)
        self.latest_new_count = len(new_items)  # ä¿å­˜æœ€æ–°æ•°é‡
        return self.latest_new_count

    def _parse_html_content(self, data: Dict) -> Dict:
        """è§£æHTMLå†…å®¹ï¼Œæå–é¡¹ç›®ä¿¡æ¯å’Œä¸­æ ‡å€™é€‰äººåˆ—è¡¨"""
        try:
            project_name = data.get("customtitle", "").replace("ä¸­æ ‡å€™é€‰äººå…¬ç¤º", "").strip()
            infocontent = data.get("infocontent", "")
            soup = BeautifulSoup(infocontent, 'html.parser')
            full_text = soup.get_text()
    
            # æå–å…¬ç¤ºæ—¶é—´
            publicity_period = ""
            pub_patterns = [
                r"å…¬ç¤º[æœŸæ—¶]ä¸º?[:ï¼š]?\s*(.+?è‡³.+?)\s*(?:\n|<|$)",
                r"å…¬ç¤ºæ—¶é—´[:ï¼š]?\s*(.+?è‡³.+?)\s*(?:\n|<|$)",
                r"å…¬ç¤ºæœŸ[:ï¼š]?\s*(.+?è‡³.+?)\s*(?:\n|<|$)"
            ]
            for pattern in pub_patterns:
                match = re.search(pattern, full_text)
                if match:
                    publicity_period = match.group(1).strip()
                    break
    
            bidders_and_prices = []
            seen_bidders = set()
    
            # è¡¨æ ¼æå–ï¼ˆå¢å¼ºç»“æ„è¯†åˆ«ï¼‰
            for table in soup.find_all('table'):
                header_text = table.get_text()
                if not any(key in header_text for key in ["ä¸­æ ‡å€™é€‰äºº", "æŠ•æ ‡äºº", "å•ä½åç§°", "æŠ¥ä»·", "ä¸‹æµ®ç‡"]):
                    continue  # ä¸å«å…³é”®è¯ï¼Œè·³è¿‡
    
                rows = table.find_all("tr")
                for row in rows:
                    cells = row.find_all(['td', 'th'])
                    if len(cells) < 2:
                        continue
    
                    cell_texts = [cell.get_text(strip=True) for cell in cells]
                    row_text = ''.join(cell_texts)
    
                    # å¯»æ‰¾åŒ…å«å…¬å¸åçš„è¡Œ
                    if any("å…¬å¸" in c or "é›†å›¢" in c for c in cell_texts):
                        for cell in cell_texts:
                            bidder = cell.strip()
                            if bidder and bidder not in seen_bidders and any(kw in bidder for kw in ["å…¬å¸", "é›†å›¢", "è®¾è®¡é™¢", "å·¥ç¨‹"]):
                                seen_bidders.add(bidder)
                                bidders_and_prices.append({"bidder": bidder, "price": "æœªæä¾›"})
    
                    # å¦‚æœåŒ…å«â€œæŠ¥ä»·â€å…³é”®è¯ï¼Œå°è¯•æå–ä»·æ ¼
                    elif any("æŠ¥ä»·" in c or "ä¸‹æµ®ç‡" in c or "%" in c for c in cell_texts):
                        prices = []
                        for c in cell_texts:
                            c = c.replace('\xa0', '').strip()
                            if re.search(r"([\d,.]+(ä¸‡å…ƒ|å…ƒ|%))", c) or "ä¸‹æµ®ç‡" in c:
                                prices.append(c)
                        # æŠŠä»·æ ¼åŒ¹é…åˆ°å·²æœ‰çš„ bidder ä¸Šï¼ˆæŒ‰é¡ºåºï¼‰
                        for i in range(min(len(prices), len(bidders_and_prices))):
                            if bidders_and_prices[i]["price"] == "æœªæä¾›":
                                bidders_and_prices[i]["price"] = prices[i]
            
            # å¦‚æœè¡¨æ ¼æœªè¯†åˆ«ï¼Œå°è¯•æ–‡æœ¬æå–ä½œä¸ºå¤‡é€‰
            if not bidders_and_prices:
                company_pattern = r'([\u4e00-\u9fa5]{2,}(å…¬å¸|é›†å›¢|è®¾è®¡é™¢|ç ”ç©¶é™¢|å·¥ç¨‹å±€|æœ‰é™å…¬å¸|è‚¡ä»½å…¬å¸))'
                price_pattern = r'(?:æŠ¥ä»·|é‡‘é¢|ä¸‹æµ®ç‡|æŠ•æ ‡æŠ¥ä»·)[ï¼š:\s]*([\d,.%ä¸‡å…ƒå…ƒ]+)'
    
                companies = re.findall(company_pattern, full_text)
                unique_companies = []
                seen = set()
                for c, _ in companies:
                    if c not in seen:
                        seen.add(c)
                        unique_companies.append(c)
    
                prices = re.findall(price_pattern, full_text)
                for i, company in enumerate(unique_companies[:5]):
                    price = prices[i] if i < len(prices) else "æœªæä¾›"
                    bidders_and_prices.append({
                        "bidder": company,
                        "price": price
                    })
    
            # æ„å»ºæœ€ç»ˆæ•°æ®ç»“æ„
            infourl = data.get("infourl", "")
            full_url = f"{self.base_url}{infourl}" if infourl.startswith("/") else infourl
    
            return {
                "project_name": project_name or "æœªçŸ¥é¡¹ç›®",
                "publicity_period": publicity_period,
                "bidders_and_prices": bidders_and_prices,
                "full_url": full_url
            }
    
        except Exception as e:
            print(f"[è§£æé”™è¯¯] {str(e)}")
            return {
                "project_name": project_name or "è§£æå¤±è´¥",
                "publicity_period": "",
                "bidders_and_prices": [{"bidder": "è§£æå¤±è´¥", "price": "è¯·æŸ¥çœ‹è¯¦æƒ…"}],
                "full_url": ""
            }


            
    def _build_message(self, record: Dict) -> str:
        """æ„å»ºé€šçŸ¥æ¶ˆæ¯"""
        try:
            parsed_data = record.get("parsed_data", {})
            raw_data = record.get("raw_data", {})
            
            # æ„å»ºä¸­æ ‡å€™é€‰äººè¡¨æ ¼
            markdown_table = ""
            bap = parsed_data.get("bidders_and_prices", [])
            
            if bap:
                table_header = "|ä¸­æ ‡å€™é€‰äºº|æŠ•æ ‡æŠ¥ä»·|\n| :----: | -------: |"
                table_rows = []
                
                for i, item in enumerate(bap):
                    bidder = item.get("bidder", "æœªæä¾›")
                    price = item.get("price", "æœªæä¾›")
                    
                    # æ ¼å¼åŒ–æŠ¥ä»·
                    formatted_price = price
                    if '%' in price:
                        # If it contains a percentage, keep it as is
                        formatted_price = price
                    elif any(char.isdigit() for char in price):
                        # Remove commas and attempt to clean numerical parts
                        clean_price_str = price.replace(',', '')
                        
                        # Try to extract the number before units (å…ƒ, ä¸‡å…ƒ) or percentage
                        # This regex attempts to find a number at the beginning or within the string,
                        # and then capture potential units or percentages at the end.
                        match_yuan = re.search(r'([\d.]+)\s*å…ƒ', clean_price_str)
                        match_wanyuan = re.search(r'([\d.]+)\s*ä¸‡å…ƒ', clean_price_str)
                        match_percent = re.search(r'([\d.]+)\s*%', clean_price_str)
                        
                        num_val = None
                        original_unit = None
                    
                        if match_wanyuan:
                            num_val = float(match_wanyuan.group(1))
                            original_unit = "ä¸‡å…ƒ"
                        elif match_yuan:
                            num_val = float(match_yuan.group(1))
                            original_unit = "å…ƒ"
                        elif match_percent:
                            formatted_price = price # Already handled by the top-level '%' check, but good for robustness
                        else:
                            # If no explicit unit, try to parse it directly as a number
                            try:
                                num_val = float(re.sub(r'[^\d.]', '', clean_price_str))
                                # Heuristic: if a raw number is very large, assume it's in yuan by default
                                if num_val > 100000: # Adjust threshold as needed, >10ä¸‡ seems like a good cutoff for yuan toä¸‡å…ƒ conversion
                                    original_unit = "å…ƒ" # Treat as raw yuan if large
                                else:
                                    original_unit = "unknown" # Small numbers, keep as is or assume yuan
                            except ValueError:
                                pass # Not a straightforward number, keep original price
                    
                        if num_val is not None:
                            if original_unit == "å…ƒ":
                                if num_val >= 10000: # Convert large yuan amounts toä¸‡å…ƒ
                                    formatted_price = f"{num_val / 10000:,.2f}ä¸‡å…ƒ"
                                else:
                                    formatted_price = f"{num_val:,.2f}å…ƒ"
                            elif original_unit == "ä¸‡å…ƒ":
                                formatted_price = f"{num_val:,.2f}ä¸‡å…ƒ"
                            elif original_unit == "unknown":
                                formatted_price = f"{num_val:,.2f}å…ƒ" # Default to yuan for smaller numbers without explicit unit
                    
                    table_rows.append(f"|{bidder}|{formatted_price}|")
                
                markdown_table = table_header + "\n" + "\n".join(table_rows)
            
            # æ„å»ºå®Œæ•´æ¶ˆæ¯
            message = (
                "## ğŸ“¢ ä¸­æ ‡å€™é€‰äººå…¬å‘Š\n\n"
                f">**ğŸ“œ æ ‡é¢˜**ï¼š{raw_data.get('title', 'æœªçŸ¥æ ‡é¢˜')}\n\n"
                f">**ğŸ“… æ—¥æœŸ**ï¼š{raw_data.get('infodate', 'æœªçŸ¥æ—¥æœŸ')}\n\n"
                f">**â³ å…¬ç¤ºæ—¶é—´**ï¼š{parsed_data.get('publicity_period', 'æœªæä¾›')}\n\n"
            )            
            if markdown_table:
                message += "**ğŸ† ä¸­æ ‡å€™é€‰äººåŠæŠ¥ä»·ï¼š**\n" + markdown_table + "\n\n"
            else:
                message += "**ğŸ† ä¸­æ ‡å€™é€‰äººï¼š**\n"
                for i, item in enumerate(bap):
                    bidder = item.get("bidder", "æœªæä¾›")
                    price = item.get("price", "æœªæä¾›")
                    message += f"{i+1}. {bidder}"
                    if price and price != "æœªæä¾›":
                        message += f" (æŠ¥ä»·: {price})"
                    message += "\n"
                message += "\n"
            
            message += f"ğŸ”— **è¯¦æƒ…é“¾æ¥**ï¼š{parsed_data.get('full_url', '')}"
            
            return message
        except Exception as e:
            print(f"[æ¶ˆæ¯æ„å»ºé”™è¯¯] æ„å»ºé€šçŸ¥æ¶ˆæ¯å¤±è´¥: {str(e)}")
            return ""

    def send_notifications(self):
        """å‘é€é€šçŸ¥"""
        if self.latest_new_count <= 0:
            return

        parsed_data = self._load_json_file(self.parsed_file)
        # ç¡®ä¿åªå¤„ç†å½“å‰æ–°å¢çš„æ•°æ®
        latest_parsed = parsed_data[-self.latest_new_count:]
        
        for record in latest_parsed:
            message = self._build_message(record)
            if not message:
                continue

            # å¸¸è§„é€šçŸ¥
            if self.webhook_url:
                self._send_wechat(message, self.webhook_url)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰"ç››è£"ä¸­æ ‡
            if "ç››è£" in message:
                # ä¸­æ ‡ç‰¹åˆ«é€šçŸ¥
                if self.webhook_zb_url:
                    self._send_wechat(f"ã€å…¥å›´æŠ•æ ‡å€™é€‰äººé€šçŸ¥ã€‘\n{message}", self.webhook_zb_url)

    def _send_wechat(self, message: str, webhook: str):
        """å‘é€ä¼ä¸šå¾®ä¿¡é€šçŸ¥"""
        try:
            payload = {
                "msgtype": "markdown_v2",
                "markdown_v2": {
                    "content": message
                }
            }
            response = requests.post(webhook, json=payload, timeout=10)
            response.raise_for_status()
            print(f"[é€šçŸ¥æˆåŠŸ] å‘é€åˆ° {webhook}")
        except Exception as e:
            print(f"[é€šçŸ¥å¤±è´¥] {str(e)}")

if __name__ == "__main__":
    import sys
    monitor = BidMonitor()

    if "--reparse-all" in sys.argv:
        monitor.reparse_all_data()
    else:
        new_count = monitor.process_and_store_data()
        if new_count > 0:
            print(f"å‘ç° {new_count} æ¡æ–°å…¬å‘Š")
            monitor.send_notifications()
        else:
            print("æ²¡æœ‰æ–°æ•°æ®éœ€è¦å¤„ç†")
